{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, first, mean, row_number, when, udf\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('ReadMariaDB') \\\n",
    ".config(\"spark.driver.memory\", \"32g\") \\\n",
    ".config(\"spark.sql.pivotMaxValues\", \"1000000\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "\n",
    "sql = \"select * from 01_sampled_games_2v2 WHERE playtime_forever IS NOT NULL AND playtime_forever > 0\"\n",
    "database = \"steam\"\n",
    "user = \"root\"\n",
    "password = \"example\"\n",
    "server = \"192.168.2.62\"\n",
    "port = 3306\n",
    "jdbc_url = f\"jdbc:mysql://{server}:{port}/{database}?permitMysqlScheme\"\n",
    "jdbc_driver = \"org.mariadb.jdbc.Driver\"\n",
    "\n",
    "# Create a data frame by reading data from Oracle via JDBC\n",
    "df = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"query\", sql) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", jdbc_driver) \\\n",
    "    .load()\n",
    "\n",
    "df = df.drop(\"playtime_2weeks\", \"dateretrieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "row_count = df.count()\n",
    "\n",
    "# Print the row count\n",
    "print(\"The DataFrame has\", row_count, \"rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample data\n",
    "# data = [(\"user1\", \"game1\", 10), (\"user2\", \"game2\", 20), (\"user1\", \"game2\", 15), (\"user2\", \"game1\", 5), \n",
    "#         (\"user1\", \"game3\", 30), (\"user2\", \"game3\", 25), (\"user3\", \"game3\", 15), (\"user3\", \"game1\", 10)]\n",
    "# df = spark.createDataFrame(data, [\"steamid\", \"appid\", \"playtime_forever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the game matrix\n",
    "game_matrix = df.groupBy(\"appid\").pivot(\"steamid\").agg(first(\"playtime_forever\"))\n",
    "game_matrix = game_matrix.orderBy(asc(\"appid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with 0\n",
    "for game_col in game_matrix.columns[1:]:\n",
    "    game_matrix = game_matrix.withColumn(game_col, game_matrix[game_col].cast(DoubleType()))\n",
    "    game_matrix = game_matrix.fillna(0.0, subset=[game_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of each column\n",
    "col_means = game_matrix.agg(*(mean(game_col).alias(game_col) for game_col in game_matrix.columns[1:])).collect()[0]\n",
    "\n",
    "# Subtract the mean from each non-zero cell in the game matrix\n",
    "for game_col in game_matrix.columns[1:]:\n",
    "    game_matrix = game_matrix.withColumn(game_col, when(game_matrix[game_col] != 0, game_matrix[game_col] - col_means[game_col]).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns with numerical values and assemble them into a vector column\n",
    "numeric_cols = game_matrix.columns[1:]\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "vector_matrix = assembler.transform(game_matrix).select(\"features\")\n",
    "\n",
    "# Compute the Pearson correlation matrix between the rows\n",
    "pearson_matrix = Correlation.corr(vector_matrix, \"features\", \"pearson\")\n",
    "corr_array = pearson_matrix.head()[0].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an index column to the game matrix\n",
    "windowSpec = Window.partitionBy(\"appid\").orderBy(\"appid\")\n",
    "game_matrix = game_matrix.withColumn(\"index\", row_number().over(windowSpec))\n",
    "game_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UDF closure to compute the weighted average\n",
    "def udf_compute_weighted_average(user_playtimes, k):\n",
    "    def compute_weighted_average(playtime, index):\n",
    "        if playtime == 0.0:\n",
    "            correlations = corr_array[index - 1]\n",
    "            tuples = sorted(list(zip(correlations, user_playtimes)), key=lambda x: x[0], reverse=True)\n",
    "            filtered_tuples = [tup for tup in tuples if tup[1] != 0.0]\n",
    "            prediction = 0.0\n",
    "            for i in range(min(k, len(filtered_tuples))):\n",
    "                prediction = prediction + filtered_tuples[i][0] * filtered_tuples[i][1]\n",
    "            return float(prediction)\n",
    "        else:\n",
    "            return 0.0\n",
    "    return udf(compute_weighted_average, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF to each user column\n",
    "k = 2\n",
    "predictions_df = game_matrix.select((\"*\"))\n",
    "for index, user in enumerate(predictions_df.columns[1:len(predictions_df.columns) - 1]):\n",
    "    user_playtimes = predictions_df.select(user).rdd.flatMap(lambda x: x).collect()\n",
    "    predictions_df = predictions_df.withColumn(user, udf_compute_weighted_average(user_playtimes, k)(predictions_df[user], predictions_df[\"index\"]))\n",
    "\n",
    "predictions_df = predictions_df.drop(\"index\")\n",
    "predictions_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e120910b4957e5cd755e2a42b93193ccb3c34461c3543db7ce9f360eefaa4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
