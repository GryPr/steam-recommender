{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import DecimalType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.functions import when, col, lit\n",
    "from pyspark.sql.functions import avg, stddev_pop\n",
    "\n",
    "spark = SparkSession.builder.appName('ReadMariaDB') \\\n",
    ".config(\"spark.driver.memory\", \"32g\") \\\n",
    ".config(\"spark.sql.pivotMaxValues\", \"1000000\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "# sql = \"select * from 01_sampled_games_2 WHERE playtime_forever IS NOT NULL AND playtime_forever > 0\"\n",
    "sql = \"select * from 01_sampled_games_2 WHERE playtime_forever IS NOT NULL\"\n",
    "database = \"steam\"\n",
    "user = \"root\"\n",
    "password = \"example\"\n",
    "server = \"192.168.2.62\"\n",
    "port = 3306\n",
    "jdbc_url = f\"jdbc:mysql://{server}:{port}/{database}?permitMysqlScheme\"\n",
    "jdbc_driver = \"org.mariadb.jdbc.Driver\"\n",
    "\n",
    "# Create a data frame by reading data from MariaDB via JDBC\n",
    "df = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"query\", sql) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", jdbc_driver) \\\n",
    "    .load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, stddev_pop, col\n",
    "\n",
    "# Calculate the per-game mean and standard deviation of the playtime column\n",
    "game_stats = df.filter(col(\"playtime_forever\") > 0).groupBy(\"appid\").agg(\n",
    "    mean(\"playtime_forever\").alias(\"game_mean_playtime\"),\n",
    "    stddev_pop(\"playtime_forever\").alias(\"game_stddev_playtime\")\n",
    ")\n",
    "\n",
    "# Normalize the playtime column on a per-game basis using z-score normalization\n",
    "df = df.join(game_stats, \"appid\")\n",
    "df = df.withColumn(\"z_score\", (col(\"playtime_forever\") - col(\"game_mean_playtime\")) / col(\"game_stddev_playtime\"))\n",
    "df = df.dropna(subset=[\"z_score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Game 1-5 Rank Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we calculate the mean and standard deviation for the playtime for each user. Then, we define dynamically define the cut points for the ratings from 1 to 5 on a per-user basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"cut_point_1\", when(col(\"game_mean_playtime\") - (col(\"game_stddev_playtime\") * 0.5) > 0, col(\"game_mean_playtime\") - (col(\"game_stddev_playtime\") * 0.5)).otherwise(0))\n",
    "df = df.withColumn(\"cut_point_2\", col(\"game_mean_playtime\"))\n",
    "df = df.withColumn(\"cut_point_3\", col(\"game_mean_playtime\") + (col(\"game_stddev_playtime\") * 0.5))\n",
    "df = df.withColumn(\"cut_point_4\", col(\"game_mean_playtime\") + col(\"game_stddev_playtime\"))\n",
    "df = df.withColumn(\"cut_point_5\", col(\"game_mean_playtime\") + (col(\"game_stddev_playtime\") * 1.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we assign ratings for each playtime record based on the cut points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"ranks\",\n",
    "    when(col(\"playtime_forever\") <= col(\"cut_point_1\"), lit(1))\n",
    "    .when((col(\"playtime_forever\") > col(\"cut_point_1\")) & (col(\"playtime_forever\") <= col(\"cut_point_2\")), lit(2))\n",
    "    .when((col(\"playtime_forever\") > col(\"cut_point_2\")) & (col(\"playtime_forever\") <= col(\"cut_point_3\")), lit(3))\n",
    "    .when((col(\"playtime_forever\") > col(\"cut_point_3\")) & (col(\"playtime_forever\") <= col(\"cut_point_4\")), lit(4))\n",
    "    .otherwise(lit(5))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steamidIndexer = StringIndexer(inputCol=\"steamid\", outputCol=\"steamidIndex\")\n",
    "model = steamidIndexer.fit(df)\n",
    "df = model.transform(df)\n",
    "\n",
    "appidIndexer = StringIndexer(inputCol=\"appid\", outputCol=\"appidIndex\")\n",
    "model = appidIndexer.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rating_col = \"ranks\"\n",
    "(training, test) = df.randomSplit([0.8, 0.2], seed=123)\n",
    "ranks = [5, 10, 15, 20, 40, 60, 80, 100, 150, 200]\n",
    "min_rmse = float('inf')\n",
    "best_rank = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    als = ALS(maxIter=10, rank=rank, regParam=0.01, coldStartStrategy='drop', userCol='steamidIndex', itemCol='appidIndex', ratingCol=selected_rating_col, implicitPrefs=True)\n",
    "    als.setSeed(123)\n",
    "    model = als.fit(training)\n",
    "\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=selected_rating_col, predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(\"Rank: \" + str(rank) + \" RMSE: \" + str(rmse))\n",
    "\n",
    "    if rmse < min_rmse:\n",
    "        min_rmse = rmse\n",
    "        best_rank = rank\n",
    "\n",
    "print(\"The best model was with rank \" + str(best_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e120910b4957e5cd755e2a42b93193ccb3c34461c3543db7ce9f360eefaa4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
